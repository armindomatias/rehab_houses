{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e1b942e",
   "metadata": {},
   "source": [
    "# Room Type Recognition using YOLOv5\n",
    "\n",
    "This notebook implements a room type recognition model using YOLOv5, a popular object detection model that we can adapt for image classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d056fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "pip install nbformat install torch torchvision ultralytics matplotlib pandas seaborn scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6be78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01350b2",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "Let's check the distribution of our data across different room types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa713d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to dataset\n",
    "DATA_PATH = \"../kaggle_room_street_data/house_data\"\n",
    "\n",
    "# Class names\n",
    "class_names = os.listdir(DATA_PATH)\n",
    "class_names = [c for c in class_names if not c.startswith(\".\")]\n",
    "print(f\"Classes: {class_names}\")\n",
    "\n",
    "# Count images per class\n",
    "class_counts = {}\n",
    "for class_name in class_names:\n",
    "    class_dir = os.path.join(DATA_PATH, class_name)\n",
    "    image_files = [f for f in os.listdir(class_dir) if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
    "    class_counts[class_name] = len(image_files)\n",
    "\n",
    "# Print and visualize class distribution\n",
    "print(\"\n",
    "Class distribution:\")\n",
    "for class_name, count in class_counts.items():\n",
    "    print(f\"{class_name}: {count} images\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(class_counts.keys(), class_counts.values())\n",
    "plt.xlabel(\"Room Type\")\n",
    "plt.ylabel(\"Number of Images\")\n",
    "plt.title(\"Images per Room Type\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd7c09a",
   "metadata": {},
   "source": [
    "## Visualize Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc400593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "plt.figure(figsize=(15, 12))\n",
    "for i, class_name in enumerate(class_names):\n",
    "    class_dir = os.path.join(DATA_PATH, class_name)\n",
    "    image_files = [f for f in os.listdir(class_dir) if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
    "    if image_files:\n",
    "        sample_image = os.path.join(class_dir, random.choice(image_files))\n",
    "        img = mpimg.imread(sample_image)\n",
    "        plt.subplot(2, 3, i+1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(class_name)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1002f49f",
   "metadata": {},
   "source": [
    "## Prepare Data for YOLOv5\n",
    "\n",
    "YOLOv5 expects data in a specific format. Let's organize our data accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16a8a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create YOLOv5 dataset structure\n",
    "YOLO_DATASET_PATH = \"./room_yolo_dataset\"\n",
    "os.makedirs(YOLO_DATASET_PATH, exist_ok=True)\n",
    "\n",
    "# Create train, val, test directories\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    for subdir in [\"images\", \"labels\"]:\n",
    "        os.makedirs(os.path.join(YOLO_DATASET_PATH, split, subdir), exist_ok=True)\n",
    "\n",
    "# Create file lists for each class\n",
    "all_images = []\n",
    "class_indices = {class_name: idx for idx, class_name in enumerate(class_names)}\n",
    "\n",
    "for class_name in class_names:\n",
    "    class_dir = os.path.join(DATA_PATH, class_name)\n",
    "    image_files = [f for f in os.listdir(class_dir) if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
    "    \n",
    "    for img_file in image_files:\n",
    "        all_images.append({\n",
    "            \"class\": class_name,\n",
    "            \"class_idx\": class_indices[class_name],\n",
    "            \"path\": os.path.join(class_dir, img_file),\n",
    "            \"filename\": img_file\n",
    "        })\n",
    "\n",
    "# Split data into train (70%), validation (15%), and test (15%) sets\n",
    "train_imgs, temp_imgs = train_test_split(all_images, test_size=0.3, random_state=42, stratify=[img[\"class\"] for img in all_images])\n",
    "val_imgs, test_imgs = train_test_split(temp_imgs, test_size=0.5, random_state=42, stratify=[img[\"class\"] for img in temp_imgs])\n",
    "\n",
    "print(f\"Train images: {len(train_imgs)}\")\n",
    "print(f\"Validation images: {len(val_imgs)}\")\n",
    "print(f\"Test images: {len(test_imgs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a8f7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prepare YOLO format data\n",
    "def prepare_yolo_data(image_list, split):\n",
    "    for img_data in image_list:\n",
    "        # Copy image to YOLO dataset\n",
    "        src_path = img_data[\"path\"]\n",
    "        dst_path = os.path.join(YOLO_DATASET_PATH, split, \"images\", img_data[\"filename\"])\n",
    "        shutil.copy(src_path, dst_path)\n",
    "        \n",
    "        # Create corresponding label file (since we are doing classification, we will use a dummy bbox)\n",
    "        label_file = os.path.join(YOLO_DATASET_PATH, split, \"labels\", os.path.splitext(img_data[\"filename\"])[0] + \".txt\")\n",
    "        \n",
    "        # Format: class_idx center_x center_y width height\n",
    "        # For classification, we will use a full-image bbox (centered at 0.5, 0.5 with width/height of 1.0)\n",
    "        with open(label_file, \"w\") as f:\n",
    "            f.write(f\"{img_data[\"class_idx\"]} 0.5 0.5 1.0 1.0\n",
    "\")\n",
    "\n",
    "# Prepare data for each split\n",
    "prepare_yolo_data(train_imgs, \"train\")\n",
    "prepare_yolo_data(val_imgs, \"val\")\n",
    "prepare_yolo_data(test_imgs, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9041f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data.yaml file for YOLOv5\n",
    "yaml_content = f\"\"\"train: {os.path.join(YOLO_DATASET_PATH, \"train\", \"images\")}\n",
    "val: {os.path.join(YOLO_DATASET_PATH, \"val\", \"images\")}\n",
    "test: {os.path.join(YOLO_DATASET_PATH, \"test\", \"images\")}\n",
    "\n",
    "nc: {len(class_names)}\n",
    "names: {class_names}\n",
    "\"\"\"\n",
    "\n",
    "with open(os.path.join(YOLO_DATASET_PATH, \"data.yaml\"), \"w\") as f:\n",
    "    f.write(yaml_content)\n",
    "\n",
    "print(\"YOLO dataset preparation complete.\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
